<!DOCTYPE html>
<html>
<head>
    <title>Voice-to-Task</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        button {
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            margin-bottom: 10px;
        }
        button:disabled {
            background-color: #cccccc;
        }
        #result {
            margin-top: 20px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
            min-height: 100px;
            background-color: #f9f9f9;
        }
        #interimResult {
            color: #666;
            font-style: italic;
            margin: 10px 0;
            min-height: 20px;
        }
        .task-detail {
            margin: 5px 0;
            padding: 5px;
            background-color: #f0f0f0;
            border-radius: 3px;
        }
        .error {
            color: #d9534f;
        }
    </style>
</head>
<body>
    <h1>Voice-to-Task</h1>
    <p>Click the button and say something like: "Call Mr. X about Topic Y by Date Z"</p>
    
    <button id="recordButton">Start Recording</button>
    <div id="interimResult"></div>
    <div id="result"></div>

    <script>
        const recordButton = document.getElementById('recordButton');
        const resultDiv = document.getElementById('result');
        const interimResultDiv = document.getElementById('interimResult');
        
        if (!('webkitSpeechRecognition' in window)) {
            resultDiv.innerHTML = '<p class="error">Speech recognition is not supported in this browser. Please try Chrome or Edge.</p>';
            recordButton.disabled = true;
        } else {
            const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.continuous = false;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
            recognition.maxAlternatives = 3;

            // Add speech adaptation for your domain
            try {
                const grammar = '#JSGF V1.0; grammar tasks; public <task> = call | email | meet | create | send;';
                const speechRecognitionList = new (window.SpeechGrammarList || window.webkitSpeechGrammarList)();
                speechRecognitionList.addFromString(grammar, 1);
                recognition.grammars = speechRecognitionList;
            } catch (e) {
                console.log('Grammar not supported:', e);
            }

            let isProcessing = false;
            
            recordButton.onclick = () => {
                if (isProcessing) return;
                
                recordButton.disabled = true;
                recordButton.textContent = 'Listening...';
                resultDiv.innerHTML = '';
                interimResultDiv.innerHTML = '<p>Listening... Speak now.</p>';
                recognition.start();
            };
            
            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Show interim results while speaking
                if (interimTranscript) {
                    interimResultDiv.innerHTML = `<p>Recognizing: "${interimTranscript}"</p>`;
                }
                
                // Process final result when done speaking
                if (finalTranscript && !isProcessing) {
                    isProcessing = true;
                    interimResultDiv.innerHTML = `<p>Processing: "${finalTranscript}"</p>`;
                    
                    // Send to Django backend
                    fetch('/api/process-voice/', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/x-www-form-urlencoded',
                            'X-CSRFToken': '{{ csrf_token }}'
                        },
                        body: `voice_text=${encodeURIComponent(finalTranscript)}`
                    })
                    .then(response => {
                        if (!response.ok) {
                            throw new Error('Network response was not ok');
                        }
                        return response.json();
                    })
                    .then(data => {
                        if (data.status === 'success') {
                            resultDiv.innerHTML = `
                                <p><strong>Task created successfully:</strong></p>
                                <div class="task-detail"><strong>Action:</strong> ${data.data.action}</div>
                                <div class="task-detail"><strong>Person:</strong> ${data.data.person || 'None'}</div>
                                <div class="task-detail"><strong>Topic:</strong> ${data.data.topic || 'None'}</div>
                                <div class="task-detail"><strong>Deadline:</strong> ${data.data.deadline || 'None'}</div>
                                <div class="voice-feedback">"${data.data.feedback}"</div>
                                <div class="task-detail"><strong>Original text:</strong> "${finalTranscript}"</div>
                            `;
                                            // Add voice feedback
                            if ('speechSynthesis' in window) {
                                const feedback = new SpeechSynthesisUtterance(data.data.feedback);
                                feedback.rate = 0.9;  // Slightly slower than normal
                                window.speechSynthesis.speak(feedback);
                            }
                        } else {
                            resultDiv.innerHTML = `<p class="error">Error: ${data.error || 'Unknown error occurred'}</p>`;
                        }
                    })
                    .catch(error => {
                        resultDiv.innerHTML = `<p class="error">Error: ${error.message || 'Failed to process request'}</p>`;
                    })
                    .finally(() => {
                        isProcessing = false;
                        recordButton.disabled = false;
                        recordButton.textContent = 'Start Recording';
                        interimResultDiv.innerHTML = '';
                    });
                }
            };
            
            recognition.onerror = (event) => {
                interimResultDiv.innerHTML = `<p class="error">Error: ${event.error}</p>`;
                recordButton.disabled = false;
                recordButton.textContent = 'Start Recording';
                isProcessing = false;
            };
            
            recognition.onend = () => {
                if (!isProcessing) {
                    interimResultDiv.innerHTML = '';
                }
            };
        }
    </script>
</body>
</html>